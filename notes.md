Things I've observed so far:

1. Open-source LLMs are still quite behind. Qwen thinks for 17k tokens on the first turn before errorring out. Format consistency is also a problem. 
2. You can fix format consistency with structured outputs, but then the models stop reasoning. Have not been able to get deepseek to emit reasoning while following structured outputs. 
